{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize     \n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, jaccard_similarity_score, accuracy_score, \\\n",
    "\t\tf1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(Callback):\n",
    "    def __init__(self, x_test, y_test):\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "        self.val_accuracies = []\n",
    "        self.val_jaccards = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        print(\"finished batch {}\".format(batch))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.x_test)))\n",
    "\n",
    "        print(val_predict)\n",
    "\n",
    "        val_predict[val_predict >= 0.5] = 1\n",
    "        val_predict[val_predict < 0.5] = 0\n",
    "        print(self.y_test.columns)\n",
    "        print(\"*****\")\n",
    "        print(val_predict)\n",
    "        print(\"*****\")\n",
    "        print(self.y_test.values)\n",
    "        print(\"*****\")\n",
    "        _val_f1 = f1_score(self.y_test.values, val_predict, average='weighted')\n",
    "        _val_recall = recall_score(self.y_test.values, val_predict, average='weighted')\n",
    "        _val_precision = precision_score(self.y_test.values, val_predict, average='weighted')\n",
    "        _val_accuracy = accuracy_score(self.y_test.values, val_predict)\n",
    "        _val_jaccard = jaccard_similarity_score(self.y_test.values, val_predict)\n",
    "\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        self.val_accuracies.append(_val_accuracy)\n",
    "        self.val_jaccards.append(_val_jaccard)\n",
    "\n",
    "        print(\"— val_f1: {} — val_precision: {} — val_recall {} — val_accuracy: {} — val_jaccard {}\" \\\n",
    "                .format(_val_f1, _val_precision, _val_recall, _val_accuracy, _val_jaccard))\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subset = None):\n",
    "    data = pd.read_csv(\"./dataset_20000.csv\")\n",
    "    if subset is not None:\n",
    "        return data.head(subset)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn(num_words, input_length):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import LSTM\n",
    "    from keras.layers.embeddings import Embedding\n",
    "    from keras.preprocessing import sequence\n",
    "\n",
    "    np.random.seed(7)\n",
    "\n",
    "    embed_dim = 128\n",
    "    lstm_out = 600\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_words, embed_dim, input_length=input_length))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(14, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = set()\n",
    "def remove_stopwords(sent):\n",
    "\ttokens = nltk.word_tokenize(sent)\n",
    "\tnew_sent = []\n",
    "\n",
    "\tfor token in tokens:\n",
    "\t\tword = token.lower()\n",
    "\t\tif word not in stop_words and len(token) > 2:\n",
    "\t\t\tif word not in word_dict:\n",
    "\t\t\t\tword_dict.add(word)\n",
    "\n",
    "\t\t\tnew_sent.append(word)\n",
    "\n",
    "\treturn new_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data(subset = 500)\n",
    "x = dataset[\"summary\"]\n",
    "y = dataset.drop([\"summary\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [remove_stopwords(sent) for sent in x.values]\n",
    "tokenizer = Tokenizer(filters='\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "# X = tokenizer.sequences_to_matrix(X, mode='tfidf')\n",
    "X = pad_sequences(X, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1808  1146  2380 ...     0     0     0]\n",
      " [  141 12561  2105 ...     0     0     0]\n",
      " [   66  2641  1493 ...     0     0     0]\n",
      " ...\n",
      " [ 3436    11   444 ...     0     0     0]\n",
      " [  788  5533  2454 ...     0     0     0]\n",
      " [48906   550   697 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metrics(X_test, Y_test)\n",
    "model = build_rnn(len(word_dict) + 1, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "finished batch 0\n",
      "finished batch 1\n",
      "finished batch 2\n",
      "finished batch 3\n",
      "finished batch 4\n",
      "finished batch 5\n",
      "finished batch 6\n",
      "finished batch 7\n",
      "finished batch 8\n",
      "finished batch 9\n",
      "finished batch 10\n",
      "finished batch 11\n",
      "finished batch 12\n",
      "finished batch 13\n",
      "finished batch 14\n",
      "finished batch 15\n",
      "finished batch 16\n",
      "finished batch 17\n",
      "finished batch 18\n",
      "finished batch 19\n",
      "finished batch 20\n",
      "finished batch 21\n",
      "finished batch 22\n",
      "finished batch 23\n",
      "finished batch 24\n",
      "finished batch 25\n",
      "finished batch 26\n",
      "finished batch 27\n",
      "finished batch 28\n",
      "finished batch 29\n",
      "finished batch 30\n",
      "finished batch 31\n",
      "finished batch 32\n",
      "finished batch 33\n",
      "finished batch 34\n",
      "finished batch 35\n",
      "finished batch 36\n",
      "finished batch 37\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=5, callbacks=[metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['acc'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "score, acc = model.evaluate(X_test, Y_test, verbose=2, batch_size= 32)\n",
    "\n",
    "print(score)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
